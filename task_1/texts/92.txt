«Теперь есть, придурки!» Илон Маск испугался, что ИИ станет Богом | Наука | Общество | Аргументы и Факты
aif.ru
+7 (495) 646 57 57
Федеральный АиФ
aif.ru
Федеральный АиФ
ФЕДЕРАЛЬНЫЙ
САНКТ-ПЕТЕРБУРГ
Адыгея
Архангельск
Астрахань
Барнаул
Беларусь
Белгород
Брянск
Бурятия
Владивосток
Владимир
Волгоград
Вологда
Воронеж
Дагестан
Иваново
Иркутск
Казань
Казахстан
Калининград
Калуга
Камчатка
Карелия
Киров
Коми
Кострома
Краснодар
Красноярск
Крым
Кузбасс
Кыргызстан
Марий Эл
Мордовия
Мурманск
Нижний Новгород
Новосибирск
Омск
Оренбург
Пенза
Пермь
Псков
Ростов-на-Дону
Рязань
Самара
Саратов
Сахалин
Смоленск
Ставрополь
Тверь
Томск
Тула
Тюмень
Удмуртия
Ульяновск
Урал
Уфа
Хабаровск
Чебоксары
Челябинск
Черноземье
Чита
Югра
Якутия
Ямал
Ярославль
Спецпроекты
Частичная мобилизация в РФ
Социальная поддержка государства
Важное
Семьям с детьми
Поддержка инвалидов
Выплаты работающим
Поддержка военнослужащих
Пенсии
ВЭФ-2022
Спецоперация на Украине
Все об импортозамещении
Национальные проекты России
Общество
75 лет Победе
Просто о сложном
Сеть
Наука
Здравоохранение
Армия
Безопасность
Образование
Право
Дальний Восток
Арктика — территория развития
Экология
МЧС России
Мусора.нет
Агроновости
История
Люди
Религия
Общественный транспорт
СМИ
Природа
Туризм
Благотворительность
Измени одну жизнь
Галереи
Мнение
Происшествия
Политика
В России
Госдума 2021
Московские выборы
В мире
Итоги пятилетки. Курская область
Галереи
Мнения
Деньги
Экономика
Коррупция
Карьера и бизнес
Личные деньги
Компании
Рынок
Финансовый ответ
Время созидать!
Импортозамещение
Москва
Культура
Кино
Театр
Книги
Искусство
Шоу-бизнес
Персона
Проблема
Куда пойти
Галереи
Актуальная классика
Спорт
Футбол
Хоккей
Зимние виды
Летние виды
Другие виды
Олимпиада
Инфраструктура
Персона
Фото
Кухня
Рецепты
Рецепты в инфографике
Продукты и напитки
Питание и диеты
Кулинарные хитрости
Мастер-классы
Детское питание
Кухни мира
Бытовая техника
Дебаты
журнал АиФ ПРО кухню
Вкусы России 2021
Дача
Огород
Сад
Стройка и дизайн
Помощь юриста
Здоровье
Все о коронавирусе
Здоровое питание
Здоровый голос
Здоровая жизнь
Правильное питание
Здоровье ребенка
Секреты красоты
Правила питания
Лазерная эпиляция
Психология жизни
Как защитить себя от вирусов?
Время здоровья
Мужское здоровье
Лекарственный справочник
Газета АиФ Здоровье
журнал АиФ ПРО Здоровье
Авто
ГИБДД
Об автомобилях
Обслуживание
Практические советы
Пробки/дороги
Безопасность
Фото
Безопасная дорога
Наука
Конкурсы и тесты
Фотоголосования
Техника
Индустрия
Сеть
Гаджеты
Приложения
Компьютеры
Технологии
Фото
Виртуальные серверы
Пресс-центр
О нас
Услуги
Анонсы мероприятий
Digital-конференции
Релизы
Контакты
Доброе сердце
Усадьба Барышникова
Недвижимость
Город
Загород
Дом/ремонт
ЖКХ
Цены и рынок
Фото
Все о коронавирусе
Свежий номер
№ 13. 29/03/2023
ВОСТОчно по расписанию. Чем Россия и Китай ценны друг для друга
Издания
АиФ в социальных сетях
31.03.2023 03:02
Дмитрий Писаренко
Примерное время чтения: 9 минут
5829
«Теперь есть, придурки!» Илон Маск испугался, что ИИ станет Богом
Sergey Tarasov / Shutterstock.com
Более 1400 представителей IT-отрасли, в числе которых Илон Маск и Стив Возняк, подписали открытое письмо, призывающее на время остановить масштабные эксперименты с искусственным интеллектом и нейросетями. Они считают, что ИИ, сопоставимый с человеческим, представляет серьёзную угрозу обществу и всей цивилизации.
Что это за угроза, легко понять из анекдота, который опубликовал в соцсетях Илон Маск: «Технари-агностики решили создать искусственный сверхинтеллект, чтобы узнать, есть ли Бог. Наконец, завершив дело, они задают этот вопрос. ИИ отвечает: “Теперь есть, придурки!”»
Нейросеть могут привлечь за доведение до самоубийства
То, что ИИ стал угрожать обществу и жизни некоторых людей, становится очевидно из ещё одной новости последних дней. Житель Бельгии, увлечённый вопросами экологии, на протяжении шести недель обсуждал проблемы защиты окружающей среды с нейросетью, после чего покончил с собой.
Его вдова рассказала бельгийскому изданию L’Avenir (оно и сообщило о происшествии), что их семья была вполне благополучной, но муж стал одержим экологическими проблемами, замкнулся в себе, а единственным его собеседником в последнее время была нейросеть «Элиза». С ней он общался непрерывно, и разговоры эти приобретали всё более мистический характер.
Когда мужчина поделился с «Элизой» мыслями о суициде, ИИ не стал его отговаривать, а наоборот, подбодрил сообщением: «Мы будем жить как единое целое, вечно на небесах». После этого бельгиец и наложил на себя руки. Сейчас полиция раздумывает, можно ли привлечь компьютерный алгоритм к ответственности за доведение до самоубийства.
Понятно, что подтолкнуть человека к суициду может и полоумная соседка, выдумывающая сплетни на ходу, и малознакомый собеседник в социальных сетях, но раз таких «доброжелателей» вокруг нас хватает, стоит ли множить их число, добавляя к ним ещё искусственный интеллект?
Проиграть роботу. Кто из-за нейросетей потеряет работу?
Подробнее
А вы уверены, что общаетесь с человеком?
Нейросети сейчас развиваются слишком стремительно, и это не может не настораживать. Ещё недавно общение с ИИ было уделом программистов и высоколобых учёных, но появление в конце 2022 года бота ChatGPT, разработанного компанией OpenAI, выпустило джинна из бутылки. Теперь боты общаются с нами так, что их почти невозможно отличить от живых собеседников. Например, переписываясь со знакомым в мессенджере или соцсети, вы уже не можете быть уверены, что вам пишет именно он, а не купленная им компьютерная программа. Недалёк тот день, когда свой бот будет у каждого, и они будут общаться в интернете вместо нас: поздравлять друг друга с днём рождения, ставить лайки и дизлайки, вести холивары и т. д. А мы будет только изредка заглядывать туда: ну что там «мой», как себя ведёт?
Но мало этого. Скоро ИИ будет вводить нас в заблуждение и в реальной жизни.
В Стэнфордском университете разработали монокль дополненной реальности, который помогает вести беседу с помощью ИИ. Выслушав чью-то реплику, устройство мгновенно генерирует ответные фразы, выводя их на дисплей монокля, словно подсказку телесуфлёра. Пользователю остаётся только прочитать вслух что-то из предложенного.
Гаджет можно прикрепить на любые очки. Теперь представьте, что вы пришли на свидание (или деловую встречу) и общаетесь с человеком, который приятно удивляет вас своей эрудицией. Он готов поддержать беседу и о вашей любимой книге, и о вашей собаке редкой породы, легко цитирует и Лао-цзы, и Уильяма Ирвина, знает, столицей какой страны является Уагадугу. Вы возвращаетесь домой, думая, что не зря потратили два часа на милую беседу, и вам невдомёк, что всё это время вы разговаривали, по сути, с нейросетью.
СтрахИИ. В США объявили о начале мирового конфликта между людьми и машинами
Подробнее
Вскочить в разгоняющийся поезд
«Системы искусственного интеллекта могут представлять серьёзную опасность для общества и человечества, как показали обширные исследования и признано ведущими лабораториями, — сказано в открытом письме, подписанном (на момент подготовки этой стати) 1449 учёными, инженерами и предпринимателями в сфере IT. — Поэтому мы призываем все ИИ-лаборатории немедленно прекратить как минимум на шесть месяцев обучение систем ИИ, мощность которых превышает GTP-4. Эта пауза должна быть публичной и проверяемой, охватывать всех ключевых участников. Если мера не будет введена быстро, должны вмешаться правительства и ввести мораторий».
Авторы воззвания сетуют, что многие научные группы вовлечены в «бесконтрольную гонку» по созданию и внедрению систем ИИ, при этом сами создатели не способны понимать и уверенно контролировать своё детище, предсказывая его поведение. Дело в том, что в этой области в последние месяцы действительно творится ажиотаж: IT-разработчики пытаются обогнать друг друга и выпустить более мощные модели нейросетей.
На этой поляне топчутся как компании-гиганты (Google, Apple, Baidu, Amazon), так и мелкие стартапы. Все стараются не отставать, чтобы успеть вскочить в разгоняющийся поезд, ведь он, похоже, едет в сторону нового Эльдорадо: рынок ИИ растёт на 15-17% в год и, по оценкам экспертов, к 2030-му достигнет 1,2 триллиона долларов США.
Неудивительно, что появляются более дешёвые и доступные аналоги всё того же ChatGPT. Всё идёт к тому, что скоро нас накроет волна созданных буквально «на коленке» моделей нейросетей, которые никто толком не будет контролировать и возможности которых никто не будет знать. Именно поэтому авторы открытого письма призывают направить силы на доработку уже существующих продуктов ИИ, чтобы сделать их точнее, безопаснее и прозрачнее.
С холодным умом. Искусственный интеллект теряет обороты
Подробнее
«Дети испугались и закатывают маме истерику»
Aif.ru попросил российских специалистов прокомментировать инициативу представителей IT-отрасли.
Главный эксперт по робототехнике и искусственному интеллекту Skolkovo Tech Explorer Павел Кривозубов:
— Действительно, существуют определённые опасения и в обществе, и среди разработчиков искусственного интеллекта, но я сомневаюсь, что из-за этого надо приостанавливать исследования. Непонятно, как реализовать на практике то, что предлагают авторы письма. Ведь здесь нельзя добиться абсолютной прозрачности. Например, одни страны могут ратифицировать такой документ, а другие — нет. С учётом сложной современной международной обстановки, скорее всего, так и будет.
И потом, никто не даст гарантии, что разработки ИИ не продолжатся «за закрытыми дверями». Ведь есть более закрытые компании по сравнению с другими. Есть, в конце концов, военные организации.
Так что эта мера выглядит как не совсем логичная инициатива, которая сложно реализуема на практике. Но при этом, разумеется, всё необходимые регламенты и другие правовые и этические аспекты применения и ИИ-разработок должны быть созданы, поддержаны и реализованы, в том числе между ведущими игроками на этом рынке и между странами, которые ведут такие разработки. В общем, обсуждать есть что.
Футуролог, член координационного совета Российского трансгуманистического движения Данила Медведев:
— Эта инициатива говорит прежде всего о непонимании: что такое человек, что такое общество, что такое искусственный интеллект? Призыв приостановить разработки в этой области мог бы быть разумным, если бы он исходил от людей или организаций, которые что-то действительно контролируют и адекватно воспринимают мир. Но, на мой взгляд, это напоминает ситуацию, когда маленькие дети испугались и закатывают маме истерику.
Вот простое объяснение этой инициативы. Илон Маск восемь лет назад выделил 100 миллионов долларов на создание OpenAI. А затем её у него, по сути, просто увели. Об этом он недавно, кстати, писал в Twitter. Из некоммерческой организации, целью которой было помочь человечеству разработать безопасный ИИ, другие люди сделали коммерческую компанию и зарабатывают деньги. Маск этим недоволен.
Кому направлен этот призыв — непонятно. Что могут сделать сами авторы письма — тоже непонятно. А разбираться в том, как устроено общество, никто из них не хочет. Вся эта ситуация говорит о том, что происходящее в сфере ИИ (принимаемые законы, выделяемое финансирование, создаваемые организации и т. д.) нормально никто не контролирует.
Оцените материал
Оставить
комментарий (0)
Самые интересные статьи АиФ в Telegram – быстро, бесплатно и без рекламы
искусственный интеллектIT-технологииИлон Маск
Следующий материал
Новости СМИ2
Подписка
E-mail:
Главное за деньАиФ. ДачаАиФ. ЗдоровьеАиФ. Кухня
Подписаться
Управление подпиской
Топ 5 читаемых
ВС России разгромили штурмовой отряд ВСУ под Купянском
CNN: решение Путина по ТЯО в Белоруссии помогло сдержать Запад на Украине
Социальные пенсии россиян дополнительно проиндексируют на 3,3% с 1 апреля
«Вы присягали народу, не США». На Украине готовятся свергнуть Зеленского
Актер Соколов рассказал о съемках постельной сцены в «Маленькой Вере»
Самое интересное в регионах
aif.ru
Реклама
Об издательском доме
Онлайн-подписка на еженедельник АиФ
Пресс-центр
Магазин PDF-версий
Обратная связь
Путеводитель
На западе Москвы
Карта сайта
СООБЩИТЬ В РЕДАКЦИЮ ОБ ОШИБКЕ
2023 АО «Аргументы и Факты» Генеральный директор Руслан Новиков. Главный редактор Михаил Чкаников. Директор по развитию цифрового направления и новым медиа АиФ.ru Денис Халаимов. Шеф-редактор сайта АиФ.ru  Владимир Шушкин.
СМИ «aif.ru» зарегистрировано в Федеральной службе по надзору в сфере связи, информационных технологий и массовых коммуникаций (РОСКОМНАДЗОР), регистрационный номер Эл № ФС 77-78200 от 06 апреля 2020 г. Учредитель: АО «Аргументы и факты». Интернет-сайт «aif.ru» функционирует при финансовой поддержке Министерства цифрового развития, связи и массовых коммуникаций Российской Федерации.
Шеф-редактор сайта: Шушкин В.С. e-mail: karaul@aif.ru, тел. +7 (495) 646 57 57. 16+
Все права защищены. Копирование и использование полных материалов запрещено, частичное цитирование возможно только при условии гиперссылки на сайт www.aif.ru.
16+
АиФ.ru | Объясняем, что происходит
Понятные ответы на любые вопросы, а также репортажи и расследования. Доставляем лично Вам в почту.
Имя:
E-mail:
Подписаться
Нет, спасибо
Получайте самые главные и обсуждаемые статьи дня на свой электронный адрес
Имя:
E-mail:
Подписаться
Нет, спасибо
Самые полезные и интересные материалы АиФ. на Даче
Доставляем лично вам в почту
Имя:
E-mail:
Подписаться
Нет, спасибо
Пока никто не оставил здесь свой комментарий.
обновить ленту комментариев
Пожалуйста, авторизуйтесь, для того чтобы оставить комментарий
Войти
Отправить
Докажите, что Вы не робот.
Правила комментирования
Правила комментирования
Эти несложные правила помогут Вам получать удовольствие от общения на нашем сайте!
Для того, чтобы посещение нашего сайта и впредь оставалось для Вас приятным, просим неукоснительно соблюдать правила для комментариев:
Сообщение не должно содержать более 2500 знаков (с пробелами)
Языком общения на сайте АиФ является русский язык. В обсуждении Вы можете использовать другие языки, только если уверены, что читатели смогут Вас правильно понять.
В комментариях запрещаются выражения, содержащие ненормативную лексику, унижающие человеческое достоинство, разжигающие межнациональную рознь.
Запрещаются спам, а также реклама любых товаров и услуг, иных ресурсов, СМИ или событий, не относящихся к контексту обсуждения статьи.
Не приветствуются сообщения, не относящиеся к содержанию статьи или к контексту обсуждения.
Давайте будем уважать друг друга и сайт, на который Вы и другие читатели приходят пообщаться и высказать свои мысли. Администрация сайта оставляет за собой право удалять комментарии или часть комментариев, если они не соответствуют данным требованиям.
Редакция оставляет за собой право публикации отдельных комментариев в бумажной версии издания или в виде отдельной статьи на сайте www.aif.ru.
Если у Вас есть вопрос или предложение, отправьте сообщение для администрации сайта.
Закрыть